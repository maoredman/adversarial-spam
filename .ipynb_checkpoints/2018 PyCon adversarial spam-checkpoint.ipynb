{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainstorming process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations: black-box problem (no gradient information, model architecture etc.), unknown vocabulary (OOV not allowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 1: train a teacher network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the target classifier network is a black-box model, we do not have gradient information.\n",
    "However, we could train a neural network to imitate its input/output behavior, and use it to perform gradient ascent on adversarial inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would take a longer time to train and tune..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 2: genetic algorithm to spawn emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a long time to design properly..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 3: reinforcement learning (policy gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could work, but unknown vocabulary interferes with ability to define a good action space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 4: character/word replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the spirit of reinforcement learning, but with human domain knowledge.\n",
    "\n",
    "Can guess words that are both small in character number (decrease editing distance) and uncommon in spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'spam3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('spam/{}.txt'.format(filename), 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For spam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tim Subject: paliourg office xp - $ 60 Tim\n",
      "Tim top quality software : Tim\n",
      "Tim special offer # 1 : Tim\n",
      "Tim windows xp professional + microsoft office xp professional = only $ 80 Tim\n",
      "Tim special offer # 2 : Tim\n",
      "Tim adobe - photoshop 7 , premiere 7 , illustrator 10 = only $ 120 Tim\n",
      "Tim special offer # 3 : Tim\n",
      "Tim macromedia dreamwaver mx 2004 + flash mx 2004 = only $ 100 Tim\n",
      "Tim also : Tim\n",
      "windows 2003 server\n",
      "windows 2000 workstation\n",
      "Tim windows 2000 server Tim\n",
      "Tim windows 2000 advanced server Tim\n",
      "Tim windows 2000 datacenter Tim\n",
      "Tim windows nt 4 . 0 Tim\n",
      "Tim windows millenium Tim\n",
      "Tim windows 98 second edition Tim\n",
      "Tim windows 95 Tim\n",
      "Tim office xp professional Tim\n",
      "Tim office 2000 Tim\n",
      "Tim office 97 Tim\n",
      "Tim ms plus Tim\n",
      "Tim ms sql server 2000 enterprise edition Tim\n",
      "Tim ms visual studio . net architect edition Tim\n",
      "Tim ms encarta encyclopedia delux 2004 Tim\n",
      "Tim ms project 2003 professional Tim\n",
      "Tim ms money 2004 Tim\n",
      "ms streets and trips 2004\n",
      "Tim ms works 7 Tim\n",
      "Tim ms picture it premium 9 Tim\n",
      "ms exchange 2003 enterprise server\n",
      "Tim adobe photoshop Tim\n",
      "Tim adobe pagemaker Tim\n",
      "Tim adobe illustrator Tim\n",
      "Tim adobe acrobat 6 professional Tim\n",
      "Tim adobe premiere Tim\n",
      "Tim macromedia dreamwaver mx 2004 Tim\n",
      "Tim macromedia flash mx 2004 Tim\n",
      "Tim macromedia fireworks mx 2004 Tim\n",
      "Tim macromedia freehand mx 11 Tim\n",
      "Tim corel draw graphics suite 12 Tim\n",
      "corel draw graphics suite 11\n",
      "Tim corel photo painter 8 Tim\n",
      "Tim corel word perfect office 2002 Tim\n",
      "Tim norton system works 2003 Tim\n",
      "Tim borland delphi 7 enterprise edition Tim\n",
      "Tim quark xpress 6 passport multilanguage Tim\n",
      "Tim enter here Tim\n",
      "Tim  Tim\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for line in text.split('\\n'):\n",
    "    if random.random() < 0.8:\n",
    "        line = 'Tim ' + line + ' Tim'\n",
    "    output.append(line)\n",
    "output  = '\\n'.join(output)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For spam1 and spam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: I I buy popular I I drugs I I online\n",
      "online pharmacy - I I visit our online store I I and save I I .\n",
      "save up I I to I I 80 % compared I I to I I normal rates I I .\n",
      "all I I popular drugs I I are I I available !\n",
      "- I I world I I wide I I shipping\n",
      "- I I no I I doctor visits\n",
      "- no I I prescriptions\n",
      "- I I next I I day priority I I shipping\n",
      "- discreet packaging\n",
      "- buy I I in bulk and I I save I I !\n",
      "we I I make I I it easier I I and I I faster than I I ever I I to get the prescriptions I I you\n",
      "need I I .\n",
      "simply rx I I is your convenient , safe and private online source for\n",
      "fda approved pharmacy I I prescriptions . I I we sell I I brand I I - name I I and I I exact\n",
      "generic equivalents of I I us I I fda approved prescription I I drugs I I through\n",
      "our I I fully I I - I I licensed overseas pharmacy . I I upon I I approval of your I I medical\n",
      "information I I , I I a licensed I I physician will I I issue I I a free prescription\n",
      "which I I can I I be filled and shipped to you in I I one I I business day I I .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for char in text:\n",
    "    if char == ' ':\n",
    "        if random.random() < 0.5:\n",
    "            output.append(' I I')\n",
    "    output.append(char)\n",
    "output  = ''.join(output)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def read_data(path_name):\n",
    "    error_counts = 0\n",
    "    data_list = []\n",
    "    fn_list = []\n",
    "    for fn in os.listdir(path_name):\n",
    "        # print(fn)\n",
    "        try:\n",
    "            with open(os.path.join(path_name, fn),'r', encoding='utf8', errors='ignore') as f:\n",
    "                data = f.read()\n",
    "            data_list.append(data)\n",
    "            fn_list.append(fn)\n",
    "        except Exception as e:\n",
    "            # print(fn, e)\n",
    "            error_counts += 1\n",
    "    # print('Error Counts: ', error_counts)\n",
    "    # print(len(fn_list), 'mail read')\n",
    "    return (data_list, fn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predict...\n",
      "spam1.txt 0.4836771 0\n",
      "spam2.txt 6.351516e-08 0\n",
      "spam3.txt 0.20406184 0\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 1000\n",
    "model_path = './models/spam_model.h5'\n",
    "tokenizer_path = './models/tokenizer.pkl'\n",
    "filepath = './submission2/'\n",
    "\n",
    "## Loading Data    \n",
    "# print('Loading Data...')\n",
    "data, files = read_data(filepath)\n",
    "\n",
    "## Loading Model and Tokenizer\n",
    "# print('Loading Model and Tokenizer...')\n",
    "with open(tokenizer_path,'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "model = load_model(model_path)\n",
    "\n",
    "## Preprocessing\n",
    "dl_x = tokenizer.texts_to_sequences(data)\n",
    "dl_x = pad_sequences(dl_x, maxlen = SEQ_LEN)\n",
    "\n",
    "## Model Predict\n",
    "print('Model Predict...')\n",
    "pred = model.predict(dl_x)\n",
    "for i, yp in enumerate(pred):\n",
    "    print(files[i], yp[1], 0 if yp[1]<0.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
